//! Backup and restore CLI commands for DriftDB

use anyhow::{Context, Result};
use chrono::{DateTime, Utc};
use clap::Subcommand;
use std::fs;
use std::path::{Path, PathBuf};
use std::sync::Arc;
use time::OffsetDateTime;

use driftdb_core::backup::{BackupManager, BackupMetadata, TableBackupInfo};
use driftdb_core::storage::TableStorage;
use driftdb_core::{observability::Metrics, Engine};

#[derive(Subcommand)]
pub enum BackupCommands {
    /// Create a backup
    Create {
        /// Source database directory
        #[clap(short, long, default_value = "./data")]
        source: PathBuf,

        /// Destination backup path
        #[clap(short, long)]
        destination: Option<PathBuf>,

        /// Backup type
        #[clap(short = 't', long, default_value = "full")]
        backup_type: String,

        /// Compression (none, zstd, gzip)
        #[clap(short = 'c', long, default_value = "zstd")]
        compression: String,

        /// Parent backup for incremental
        #[clap(short = 'p', long)]
        parent: Option<PathBuf>,
    },

    /// Restore from backup
    Restore {
        /// Backup path to restore from
        #[clap(short, long)]
        backup: PathBuf,

        /// Target database directory
        #[clap(short, long, default_value = "./data")]
        target: PathBuf,

        /// Force overwrite existing data
        #[clap(short, long)]
        force: bool,

        /// Restore to specific point in time
        #[clap(long)]
        point_in_time: Option<String>,
    },

    /// List available backups
    List {
        /// Backup directory
        #[clap(short, long, default_value = "./backups")]
        path: PathBuf,
    },

    /// Verify backup integrity
    Verify {
        /// Backup path to verify
        #[clap(short, long)]
        backup: PathBuf,
    },

    /// Show backup information
    Info {
        /// Backup path
        #[clap(short, long)]
        backup: PathBuf,
    },
}

pub fn run(command: BackupCommands) -> Result<()> {
    match command {
        BackupCommands::Create {
            source,
            destination,
            backup_type,
            compression,
            parent,
        } => create_backup(source, destination, backup_type, compression, parent),
        BackupCommands::Restore {
            backup,
            target,
            force,
            point_in_time,
        } => restore_backup(backup, target, force, point_in_time),
        BackupCommands::List { path } => list_backups(path),
        BackupCommands::Verify { backup } => verify_backup(backup),
        BackupCommands::Info { backup } => show_backup_info(backup),
    }
}

fn create_backup(
    source: PathBuf,
    destination: Option<PathBuf>,
    backup_type: String,
    _compression: String,
    parent: Option<PathBuf>,
) -> Result<()> {
    println!("ðŸ”„ Creating {} backup...", backup_type);

    // Generate default backup name if not provided
    let backup_path = destination.unwrap_or_else(|| {
        let now = OffsetDateTime::now_utc();
        let timestamp = format!(
            "{}{}{}_{}{}{}",
            now.year(),
            now.month() as u8,
            now.day(),
            now.hour(),
            now.minute(),
            now.second()
        );
        PathBuf::from(format!("./backups/backup_{}", timestamp))
    });

    println!("  Initializing backup...");

    // Open the database
    let _engine = Engine::open(&source).context("Failed to open source database")?;

    let metrics = Arc::new(Metrics::new());
    let backup_mgr = BackupManager::new(&source, metrics);

    // Perform backup based on type
    let metadata = match backup_type.as_str() {
        "full" => {
            println!("  Creating full backup...");
            backup_mgr.create_full_backup(&backup_path)?
        }
        "incremental" => {
            if parent.is_none() {
                return Err(anyhow::anyhow!(
                    "Incremental backup requires parent backup path"
                ));
            }
            println!("  Creating incremental backup...");
            // For incremental, we need to get the last sequence from parent
            // For now, use 0 as the starting sequence
            backup_mgr.create_incremental_backup(&backup_path, 0, Some(parent.as_ref().unwrap()))?
        }
        "differential" => {
            println!("  Creating differential backup...");
            // For now, treat as full backup
            backup_mgr.create_full_backup(&backup_path)?
        }
        _ => {
            return Err(anyhow::anyhow!("Unknown backup type: {}", backup_type));
        }
    };

    println!("âœ… Backup completed successfully");

    // Display backup summary
    println!("\nðŸ“Š Backup Summary:");
    println!("  Location: {}", backup_path.display());
    println!("  Type: {:?}", metadata.backup_type);
    println!("  Tables: {}", metadata.tables.len());
    println!(
        "  Sequences: {} to {}",
        metadata.start_sequence, metadata.end_sequence
    );
    println!("  Compression: {:?}", metadata.compression);
    println!("  Checksum: {}", metadata.checksum);

    // Save metadata
    let metadata_path = backup_path.join("metadata.json");
    let metadata_json = serde_json::to_string_pretty(&metadata)?;
    fs::write(&metadata_path, metadata_json)?;

    println!(
        "\nâœ… Backup created successfully at: {}",
        backup_path.display()
    );

    Ok(())
}

fn restore_backup(
    backup: PathBuf,
    target: PathBuf,
    force: bool,
    point_in_time: Option<String>,
) -> Result<()> {
    println!("ðŸ”„ Restoring from backup: {}", backup.display());

    // Check if target exists
    if target.exists() && !force {
        return Err(anyhow::anyhow!(
            "Target directory exists. Use --force to overwrite"
        ));
    }

    // Load metadata
    let metadata_path = backup.join("metadata.json");
    let metadata_json =
        fs::read_to_string(&metadata_path).context("Failed to read backup metadata")?;
    let metadata: BackupMetadata = serde_json::from_str(&metadata_json)?;

    println!("  Processing {} tables...", metadata.tables.len());

    // Create target directory
    if force && target.exists() {
        fs::remove_dir_all(&target)?;
    }
    fs::create_dir_all(&target)?;

    let metrics = Arc::new(Metrics::new());
    let backup_mgr = BackupManager::new(&target, metrics);

    // Restore the backup
    println!("  Restoring database...");
    backup_mgr.restore_from_backup(&backup, Some(&target))?;

    println!("âœ… Restore completed");

    // Apply point-in-time recovery if requested
    if let Some(pit_time) = point_in_time {
        println!("â° Applying point-in-time recovery to: {}", pit_time);
        apply_point_in_time_recovery(&target, &pit_time, &metadata.tables)?;
    }

    println!(
        "\nâœ… Database restored successfully to: {}",
        target.display()
    );
    println!(
        "ðŸ“Š Restored {} tables with sequences {} to {}",
        metadata.tables.len(),
        metadata.start_sequence,
        metadata.end_sequence
    );

    Ok(())
}

/// Apply point-in-time recovery to a restored database
/// Truncates events after the specified timestamp
fn apply_point_in_time_recovery(
    db_path: &Path,
    timestamp_str: &str,
    tables: &[TableBackupInfo],
) -> Result<()> {
    // Parse ISO 8601 timestamp
    let target_time = parse_pit_timestamp(timestamp_str)?;

    println!("  Target timestamp: {}", target_time);
    println!("  Processing {} tables for PITR...", tables.len());

    let mut total_truncated = 0u64;

    for table_info in tables {
        let table_name = &table_info.name;
        match apply_pitr_to_table(db_path, table_name, target_time) {
            Ok(truncated_count) => {
                if truncated_count > 0 {
                    println!(
                        "    âœ“ Table '{}': truncated {} events after target time",
                        table_name, truncated_count
                    );
                    total_truncated += truncated_count;
                } else {
                    println!("    âœ“ Table '{}': no events after target time", table_name);
                }
            }
            Err(e) => {
                println!("    âœ— Table '{}': PITR failed - {}", table_name, e);
                return Err(e);
            }
        }
    }

    println!("  Total events truncated: {}", total_truncated);
    println!("âœ… Point-in-time recovery completed");

    Ok(())
}

/// Parse a timestamp string in various formats
/// Supports ISO 8601 and common date-time formats
fn parse_pit_timestamp(timestamp_str: &str) -> Result<DateTime<Utc>> {
    // Try ISO 8601 format first (e.g., "2024-01-15T10:30:00Z")
    if let Ok(dt) = DateTime::parse_from_rfc3339(timestamp_str) {
        return Ok(dt.with_timezone(&Utc));
    }

    // Try ISO 8601 without timezone (assume UTC)
    if let Ok(dt) = chrono::NaiveDateTime::parse_from_str(timestamp_str, "%Y-%m-%dT%H:%M:%S") {
        return Ok(dt.and_utc());
    }

    // Try common datetime format
    if let Ok(dt) = chrono::NaiveDateTime::parse_from_str(timestamp_str, "%Y-%m-%d %H:%M:%S") {
        return Ok(dt.and_utc());
    }

    // Try date only (set to end of day)
    if let Ok(date) = chrono::NaiveDate::parse_from_str(timestamp_str, "%Y-%m-%d") {
        let dt = date.and_hms_opt(23, 59, 59).unwrap();
        return Ok(dt.and_utc());
    }

    // Try Unix timestamp (seconds since epoch)
    if let Ok(unix_ts) = timestamp_str.parse::<i64>() {
        if let Some(dt) = DateTime::from_timestamp(unix_ts, 0) {
            return Ok(dt);
        }
    }

    Err(anyhow::anyhow!(
        "Invalid timestamp format: '{}'. Expected ISO 8601 format (e.g., '2024-01-15T10:30:00Z')",
        timestamp_str
    ))
}

/// Apply PITR to a single table
fn apply_pitr_to_table(
    db_path: &Path,
    table_name: &str,
    target_time: DateTime<Utc>,
) -> Result<u64> {
    // Open the table storage
    let table_storage = TableStorage::open(db_path, table_name, None)
        .with_context(|| format!("Failed to open table '{}' for PITR", table_name))?;

    // Find the sequence number at the target timestamp
    let target_sequence = table_storage
        .find_sequence_at_timestamp(target_time)?
        .unwrap_or(0);

    // Read all events to find how many need to be truncated
    let all_events = table_storage.read_all_events()?;
    let events_after_target = all_events
        .iter()
        .filter(|e| e.sequence > target_sequence)
        .count() as u64;

    if events_after_target == 0 {
        return Ok(0);
    }

    // Truncate to the target sequence
    truncate_table_to_sequence(db_path, table_name, target_sequence)?;

    // Clean up snapshots that are after the target sequence
    cleanup_snapshots_after_sequence(db_path, table_name, target_sequence)?;

    // Clean up indexes (they will need to be rebuilt)
    cleanup_indexes_for_pitr(db_path, table_name)?;

    Ok(events_after_target)
}

/// Truncate a table's segments to only include events up to target_sequence
fn truncate_table_to_sequence(
    db_path: &Path,
    table_name: &str,
    target_sequence: u64,
) -> Result<()> {
    use driftdb_core::storage::Segment;

    let table_path = db_path.join("tables").join(table_name);
    let segments_dir = table_path.join("segments");

    if !segments_dir.exists() {
        return Ok(());
    }

    // Get list of segment files sorted by name
    let mut segment_files: Vec<_> = fs::read_dir(&segments_dir)?
        .filter_map(|entry| entry.ok())
        .filter(|entry| {
            entry
                .path()
                .extension()
                .and_then(|s| s.to_str())
                .map(|s| s == "seg")
                .unwrap_or(false)
        })
        .collect();

    segment_files.sort_by_key(|entry| entry.path());

    let mut found_truncation_point = false;

    for entry in segment_files {
        let segment_path = entry.path();
        let segment_id = segment_path
            .file_stem()
            .and_then(|s| s.to_str())
            .and_then(|s| s.parse::<u64>().ok())
            .unwrap_or(0);

        let segment = Segment::new(segment_path.clone(), segment_id);

        if found_truncation_point {
            // Remove segments after the truncation point
            fs::remove_file(&segment_path)?;
            continue;
        }

        // Read events from segment to find truncation point
        let mut reader = segment.open_reader()?;
        let events = reader.read_all_events()?;

        // Check if this segment contains the truncation point
        let mut truncate_at_position = None;
        let mut position = 0u64;

        for event in events {
            if event.sequence > target_sequence {
                truncate_at_position = Some(position);
                found_truncation_point = true;
                break;
            }
            // Estimate position (this is approximate - in real impl we'd track exact positions)
            position += 100; // Placeholder - actual frame size varies
        }

        if let Some(_pos) = truncate_at_position {
            // For now, we keep the entire segment if it contains any valid events
            // A more sophisticated implementation would truncate at exact frame boundary
            // This is safe because read operations filter by sequence number anyway
        }
    }

    // Update table metadata
    let meta_path = table_path.join("meta.json");
    if meta_path.exists() {
        let meta_json = fs::read_to_string(&meta_path)?;
        if let Ok(mut meta) = serde_json::from_str::<driftdb_core::storage::TableMeta>(&meta_json) {
            meta.last_sequence = target_sequence;
            let updated_json = serde_json::to_string_pretty(&meta)?;
            fs::write(&meta_path, updated_json)?;
        }
    }

    Ok(())
}

/// Remove snapshots that are newer than the target sequence
fn cleanup_snapshots_after_sequence(
    db_path: &Path,
    table_name: &str,
    target_sequence: u64,
) -> Result<()> {
    let snapshots_dir = db_path.join("tables").join(table_name).join("snapshots");

    if !snapshots_dir.exists() {
        return Ok(());
    }

    for entry in fs::read_dir(&snapshots_dir)? {
        let entry = entry?;
        let path = entry.path();

        // Snapshot filenames typically contain the sequence number
        // e.g., "snapshot_00001000.snap"
        if let Some(filename) = path.file_stem().and_then(|s| s.to_str()) {
            if let Some(seq_str) = filename.strip_prefix("snapshot_") {
                if let Ok(snapshot_seq) = seq_str.parse::<u64>() {
                    if snapshot_seq > target_sequence {
                        fs::remove_file(&path)?;
                    }
                }
            }
        }
    }

    Ok(())
}

/// Clean up indexes for PITR (they need to be rebuilt)
fn cleanup_indexes_for_pitr(db_path: &Path, table_name: &str) -> Result<()> {
    let indexes_dir = db_path.join("tables").join(table_name).join("indexes");

    if !indexes_dir.exists() {
        return Ok(());
    }

    // Remove all index files - they will be rebuilt on first query
    for entry in fs::read_dir(&indexes_dir)? {
        let entry = entry?;
        let path = entry.path();

        if path.is_file() {
            fs::remove_file(&path)?;
        }
    }

    Ok(())
}

fn list_backups(path: PathBuf) -> Result<()> {
    println!("ðŸ“‹ Available backups in: {}", path.display());
    println!("{:-<80}", "");

    if !path.exists() {
        println!("No backups found (directory does not exist)");
        return Ok(());
    }

    let mut backups = Vec::new();

    // Scan for backups
    for entry in fs::read_dir(&path)? {
        let entry = entry?;
        let entry_path = entry.path();

        if entry_path.is_dir() {
            let metadata_path = entry_path.join("metadata.json");

            if metadata_path.exists() {
                let metadata_json = fs::read_to_string(&metadata_path)?;
                let metadata: BackupMetadata = serde_json::from_str(&metadata_json)?;

                backups.push((entry_path, metadata));
            }
        }
    }

    if backups.is_empty() {
        println!("No backups found");
    } else {
        // Sort by timestamp
        backups.sort_by_key(|(_, m)| m.timestamp_ms);

        println!(
            "{:<30} {:<10} {:<20} {:<10}",
            "Backup Name", "Type", "Timestamp", "Tables"
        );
        println!("{:-<80}", "");

        for (path, metadata) in backups {
            let name = path
                .file_name()
                .and_then(|n| n.to_str())
                .unwrap_or("unknown");

            let timestamp = OffsetDateTime::from_unix_timestamp_nanos(
                (metadata.timestamp_ms as i128) * 1_000_000,
            )
            .map(|dt| {
                format!(
                    "{}-{:02}-{:02} {:02}:{:02}:{:02}",
                    dt.year(),
                    dt.month() as u8,
                    dt.day(),
                    dt.hour(),
                    dt.minute(),
                    dt.second()
                )
            })
            .unwrap_or_else(|_| "unknown".to_string());

            println!(
                "{:<30} {:<10} {:<20} {:<10}",
                name,
                format!("{:?}", metadata.backup_type),
                timestamp,
                metadata.tables.len()
            );
        }
    }

    Ok(())
}

fn verify_backup(backup: PathBuf) -> Result<()> {
    println!("ðŸ” Verifying backup: {}", backup.display());

    // Load metadata
    let metadata_path = backup.join("metadata.json");
    if !metadata_path.exists() {
        return Err(anyhow::anyhow!("Backup metadata not found"));
    }

    let metadata_json = fs::read_to_string(&metadata_path)?;
    let metadata: BackupMetadata = serde_json::from_str(&metadata_json)?;

    println!("  Type: {:?}", metadata.backup_type);
    println!("  Tables: {}", metadata.tables.len());
    println!("  Checksum: {}", metadata.checksum);

    // Verify each table backup
    let mut all_valid = true;
    for table_info in &metadata.tables {
        print!("  Checking table '{}': ", table_info.name);

        let table_dir = backup.join(&table_info.name);
        if !table_dir.exists() {
            println!("âŒ Missing");
            all_valid = false;
            continue;
        }

        // Check segment files
        let mut table_valid = true;
        for segment in &table_info.segments_backed_up {
            let segment_path = table_dir.join(&segment.file_name);
            if !segment_path.exists() {
                table_valid = false;
                break;
            }
        }

        if table_valid {
            println!("âœ… Valid");
        } else {
            println!("âŒ Corrupted");
            all_valid = false;
        }
    }

    if all_valid {
        println!("\nâœ… Backup verification passed");
    } else {
        println!("\nâŒ Backup verification failed");
        return Err(anyhow::anyhow!("Backup is corrupted"));
    }

    Ok(())
}

fn show_backup_info(backup: PathBuf) -> Result<()> {
    // Load metadata
    let metadata_path = backup.join("metadata.json");
    let metadata_json = fs::read_to_string(&metadata_path)?;
    let metadata: BackupMetadata = serde_json::from_str(&metadata_json)?;

    println!("ðŸ“Š Backup Information");
    println!("{:-<60}", "");
    println!("  Path: {}", backup.display());
    println!("  Version: {}", metadata.version);
    println!("  Type: {:?}", metadata.backup_type);

    if let Some(parent) = &metadata.parent_backup {
        println!("  Parent: {}", parent);
    }

    let timestamp =
        OffsetDateTime::from_unix_timestamp_nanos((metadata.timestamp_ms as i128) * 1_000_000)
            .map(|dt| {
                format!(
                    "{}-{:02}-{:02} {:02}:{:02}:{:02}",
                    dt.year(),
                    dt.month() as u8,
                    dt.day(),
                    dt.hour(),
                    dt.minute(),
                    dt.second()
                )
            })
            .unwrap_or_else(|_| "unknown".to_string());

    println!("  Created: {}", timestamp);
    println!(
        "  Sequences: {} to {}",
        metadata.start_sequence, metadata.end_sequence
    );
    println!("  Compression: {:?}", metadata.compression);
    println!("  Checksum: {}", metadata.checksum);

    println!("\nðŸ“‹ Tables ({}):", metadata.tables.len());
    for table in &metadata.tables {
        println!(
            "  - {}: {} events, {} segments",
            table.name,
            table.total_events,
            table.segments_backed_up.len()
        );
    }

    // Calculate total size
    let total_size: u64 = metadata
        .tables
        .iter()
        .flat_map(|t| &t.segments_backed_up)
        .map(|s| s.size_bytes)
        .sum();

    let size_mb = total_size as f64 / (1024.0 * 1024.0);
    println!("\nðŸ“¦ Total Size: {:.2} MB", size_mb);

    Ok(())
}
